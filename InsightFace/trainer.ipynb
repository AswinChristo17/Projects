{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "me_path = r\"D:\\DB\\face_reg\\mtcnn_mod\\my_face\"\n",
    "other_path = r\"D:\\DB\\face_reg\\mtcnn_mod\\others\"\n",
    "\n",
    "me_images = [os.path.join(me_path, f) for f in os.listdir(me_path) if f.endswith(\".jpg\")]\n",
    "other_images = [os.path.join(other_path, f) for f in os.listdir(other_path) if f.endswith(\".jpg\")]\n",
    "\n",
    "positive_pairs = [(me_images[i], me_images[j], 1) \n",
    "                  for i in range(len(me_images)) for j in range(i+1, len(me_images))]\n",
    "\n",
    "negative_pairs = [(random.choice(me_images), random.choice(other_images), 0) for _ in range(len(positive_pairs))]\n",
    "\n",
    "pairs = positive_pairs + negative_pairs\n",
    "df = pd.DataFrame(pairs, columns=[\"Image1\", \"Image2\", \"Label\"])\n",
    "df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, known_dir, unknown_dir):\n",
    "        self.detector = MTCNN()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        \n",
    "        # Process known faces (label 1)\n",
    "        for img_name in os.listdir(known_dir):\n",
    "            if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(known_dir, img_name)\n",
    "                face_tensor = self._process_image(img_path)\n",
    "                if face_tensor is not None:\n",
    "                    self.data.append(face_tensor)\n",
    "                    self.labels.append(1)\n",
    "                    self.names.append(img_name.split('.')[0])\n",
    "        \n",
    "        # Process unknown faces (label 0)\n",
    "        for img_name in os.listdir(unknown_dir):\n",
    "            if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(unknown_dir, img_name)\n",
    "                face_tensor = self._process_image(img_path)\n",
    "                if face_tensor is not None:\n",
    "                    self.data.append(face_tensor)\n",
    "                    self.labels.append(0)\n",
    "                    self.names.append(\"unknown\")\n",
    "    \n",
    "    def _process_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        faces = self.detector.detect_faces(img_rgb)\n",
    "        if faces:\n",
    "            x, y, w, h = faces[0]['box']\n",
    "            face = img_rgb[y:y+h, x:x+w]\n",
    "            face_pil = Image.fromarray(face)\n",
    "            face_tensor = self.transform(face_pil)\n",
    "            return face_tensor\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.names[idx]\n",
    "\n",
    "class FaceRecognitionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceRecognitionModel, self).__init__()\n",
    "        # Load pretrained MagFace model\n",
    "        self.backbone = torch.hub.load('deepinsight/insightface', 'magface_iresnet50')\n",
    "        \n",
    "        # Freeze backbone layers\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Add classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)  # 2 classes: known vs unknown\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for faces, labels, _ in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            faces, labels = faces.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(faces)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_preds.extend(predicted.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for faces, labels, _ in val_loader:\n",
    "                faces, labels = faces.to(device), labels.to(device)\n",
    "                outputs = model(faces)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Training Loss: {epoch_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Recall: {recall:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': val_loss,\n",
    "            }, 'best_face_recognition_model.pth')\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(precisions, label='Precision')\n",
    "    plt.plot(recalls, label='Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.title('Precision and Recall')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Create datasets\n",
    "    dataset = FaceDataset(known_dir=r\"D:\\DB\\face_reg\\mtcnn_mod\\my_face\", unknown_dir=r\"D:\\DB\\face_reg\\mtcnn_mod\\others\")\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = FaceRecognitionModel()\n",
    "    \n",
    "    # Train model\n",
    "    train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "    \n",
    "    model.eval()\n",
    "    known_embeddings = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for face, label, name in dataset:\n",
    "            if label == 1:  \n",
    "                face = face.unsqueeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                    face = face.cuda()\n",
    "                embedding = model.backbone(face).cpu().numpy()\n",
    "                known_embeddings[name] = embedding\n",
    "    \n",
    "    with open('known_face_embeddings.pkl', 'wb') as f:\n",
    "        pickle.dump(known_embeddings, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, known_dir, unknown_dir):\n",
    "        self.face_app = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        \n",
    "        print(\"Processing known faces...\")\n",
    "        for img_name in os.listdir(known_dir):\n",
    "            if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(known_dir, img_name)\n",
    "                face_tensor = self._process_image(img_path)\n",
    "                if face_tensor is not None:\n",
    "                    self.data.append(face_tensor)\n",
    "                    self.labels.append(1)\n",
    "                    self.names.append(img_name.split('.')[0])\n",
    "        \n",
    "        print(\"Processing unknown faces...\")\n",
    "        for img_name in os.listdir(unknown_dir):\n",
    "            if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(unknown_dir, img_name)\n",
    "                face_tensor = self._process_image(img_path)\n",
    "                if face_tensor is not None:\n",
    "                    self.data.append(face_tensor)\n",
    "                    self.labels.append(0)\n",
    "                    self.names.append(\"unknown\")\n",
    "    \n",
    "    def _process_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image {img_path}\")\n",
    "            return None\n",
    "            \n",
    "        faces = self.face_app.get(img)\n",
    "        if len(faces) > 0:\n",
    "            bbox = faces[0].bbox.astype(int)\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            if face.size == 0:\n",
    "                return None\n",
    "                \n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face_pil = Image.fromarray(face_rgb)\n",
    "            face_tensor = self.transform(face_pil)\n",
    "            return face_tensor\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.names[idx]\n",
    "\n",
    "class FaceRecognitionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceRecognitionModel, self).__init__()\n",
    "        # Initialize InsightFace model for feature extraction\n",
    "        self.face_app = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        \n",
    "        # Feature dimension from InsightFace model\n",
    "        feature_dim = 512\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)  # 2 classes: known vs unknown\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convert tensor to numpy for InsightFace\n",
    "        batch_size = x.size(0)\n",
    "        features = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img = (x[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "            faces = self.face_app.get(img)\n",
    "            if faces:\n",
    "                feat = torch.from_numpy(faces[0].embedding).float()\n",
    "                features.append(feat)\n",
    "            else:\n",
    "                # If no face detected, use zero vector\n",
    "                features.append(torch.zeros(512))\n",
    "        \n",
    "        features = torch.stack(features)\n",
    "        if x.is_cuda:\n",
    "            features = features.cuda()\n",
    "        \n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for faces, labels, _ in tqdm(train_loader, desc='Training'):\n",
    "            try:\n",
    "                faces, labels = faces.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(faces)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_preds.extend(predicted.cpu().numpy())\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error in training batch: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for faces, labels, _ in tqdm(val_loader, desc='Validation'):\n",
    "                try:\n",
    "                    faces, labels = faces.to(device), labels.to(device)\n",
    "                    outputs = model(faces)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_preds.extend(predicted.cpu().numpy())\n",
    "                    val_labels.extend(labels.cpu().numpy())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        try:\n",
    "            precision, recall, _, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            \n",
    "            print(f'Training Loss: {epoch_loss:.4f}')\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            print(f'Precision: {precision:.4f}')\n",
    "            print(f'Recall: {recall:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(\"Saving best model...\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'val_loss': val_loss,\n",
    "                }, 'best_face_recognition_model.pth')\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Plot training curves\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(precisions, label='Precision')\n",
    "        plt.plot(recalls, label='Recall')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.title('Precision and Recall')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting curves: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Check if directories exist\n",
    "        if not os.path.exists(r\"D:\\DB\\face_reg\\mtcnn_mod\\my_face\"):\n",
    "            raise FileNotFoundError(\"Directory 'dataset/my' not found\")\n",
    "        if not os.path.exists(r\"D:\\DB\\face_reg\\mtcnn_mod\\others\"):\n",
    "            raise FileNotFoundError(\"Directory 'dataset/other' not found\")\n",
    "            \n",
    "        print(\"Creating datasets...\")\n",
    "        dataset = FaceDataset(known_dir=r\"D:\\DB\\face_reg\\mtcnn_mod\\my_face\", unknown_dir=r\"D:\\DB\\face_reg\\mtcnn_mod\\others\")\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            raise ValueError(\"No valid face images found in the dataset\")\n",
    "            \n",
    "        print(f\"Total dataset size: {len(dataset)}\")\n",
    "        \n",
    "        # Split dataset\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        print(f\"Training set size: {len(train_dataset)}\")\n",
    "        print(f\"Validation set size: {len(val_dataset)}\")\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        print(\"Initializing model...\")\n",
    "        model = FaceRecognitionModel()\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Starting training...\")\n",
    "        train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "        \n",
    "        # Save the face embeddings for known faces\n",
    "        print(\"Saving face embeddings...\")\n",
    "        model.eval()\n",
    "        known_embeddings = {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for face, label, name in dataset:\n",
    "                if label == 1:  # Known face\n",
    "                    face = face.unsqueeze(0)\n",
    "                    if torch.cuda.is_available():\n",
    "                        face = face.cuda()\n",
    "                    # Get embeddings using InsightFace\n",
    "                    img = (face[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "                    faces = model.face_app.get(img)\n",
    "                    if faces:\n",
    "                        embedding = faces[0].embedding\n",
    "                        known_embeddings[name] = embedding\n",
    "        \n",
    "        # Save embeddings\n",
    "        with open('known_face_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(known_embeddings, f)\n",
    "            \n",
    "        print(\"Training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Loading known embeddings...\n",
      "Recognizing face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aswin Christo\\AppData\\Local\\Temp\\ipykernel_21860\\428504126.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Aswin Christo/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Recognition Result: Unknown\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Load the trained model\n",
    "class FaceRecognitionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceRecognitionModel, self).__init__()\n",
    "        self.face_app = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        feature_dim = 512\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Load model checkpoint\n",
    "def load_model(model_path):\n",
    "    model = FaceRecognitionModel()\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load known face embeddings\n",
    "def load_known_embeddings(embedding_path):\n",
    "    with open(embedding_path, 'rb') as f:\n",
    "        known_embeddings = pickle.load(f)\n",
    "    return known_embeddings\n",
    "\n",
    "# Process image and extract face embedding\n",
    "def extract_face_embedding(image_path, face_app):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to read image {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    faces = face_app.get(img)\n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected in the image.\")\n",
    "        return None, None\n",
    "    \n",
    "    embedding = faces[0].embedding\n",
    "    return embedding, img\n",
    "\n",
    "# Recognize face\n",
    "def recognize_face(image_path, model, known_embeddings, threshold=0.6):\n",
    "    face_app = FaceAnalysis(providers=['CPUExecutionProvider'])\n",
    "    face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "    \n",
    "    embedding, img = extract_face_embedding(image_path, face_app)\n",
    "    if embedding is None:\n",
    "        return \"No face detected\"\n",
    "    \n",
    "    # Compare with known embeddings\n",
    "    min_dist = float('inf')\n",
    "    best_match = \"Unknown\"\n",
    "    \n",
    "    for name, known_embedding in known_embeddings.items():\n",
    "        dist = np.linalg.norm(embedding - known_embedding)\n",
    "        if dist < min_dist and dist < threshold:\n",
    "            min_dist = dist\n",
    "            best_match = name\n",
    "    \n",
    "    return best_match\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"best_face_recognition_model.pth\"\n",
    "    embedding_path = \"known_face_embeddings.pkl\"\n",
    "    image_path = r\"C:\\Users\\Aswin Christo\\Pictures\\Camera Roll\\WIN_20250206_15_27_15_Pro.jpg\"  # Change to your test image path\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"Loading known embeddings...\")\n",
    "    known_embeddings = load_known_embeddings(embedding_path)\n",
    "    print(\"Recognizing face...\")\n",
    "    result = recognize_face(image_path, model, known_embeddings)\n",
    "    print(f\"Recognition Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
